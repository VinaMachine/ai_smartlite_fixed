import { describe, test, expect, beforeAll } from '@jest/globals';
import { gatewayClient, asrClient, llmClient, ttsClient } from '../../shared/client';
import { fixtures } from '../../shared/fixtures';
import { db } from '../../shared/database';

describe('E2E: Complete Voice Assistant Flow', () => {
  beforeAll(async () => {
    await db.cleanup(['transcriptions', 'llm_conversations', 'llm_messages', 'tts_requests']);
  });

  test('should process audio through ASR → LLM → TTS pipeline', async () => {
    // Step 1: Transcribe audio (ASR)
    console.log('Step 1: Transcribing audio...');
    const transcriptionData = fixtures.transcription.valid();
    const transcription = await asrClient.post('/api/v1/transcribe', transcriptionData);
    
    expect(transcription.status).toBe(201);
    const transcriptionId = transcription.data.id;
    expect(transcriptionId).toBeDefined();

    // Wait for transcription to complete (in real scenario)
    // For testing, we'll simulate with the fixture text
    const transcribedText = transcriptionData.text;

    // Step 2: Process with LLM
    console.log('Step 2: Processing with LLM...');
    const conversation = await llmClient.post('/api/v1/conversations', 
      fixtures.llmConversation.valid());
    const conversationId = conversation.data.id;

    const userMessage = await llmClient.post(
      `/api/v1/conversations/${conversationId}/messages`,
      { role: 'user', content: transcribedText }
    );

    expect(userMessage.status).toBe(201);
    expect(userMessage.data.role).toBe('user');

    // Get LLM response (would be generated by the service)
    const conversationHistory = await llmClient.get(
      `/api/v1/conversations/${conversationId}`
    );
    expect(conversationHistory.data.messages.length).toBeGreaterThan(0);

    // Step 3: Synthesize response to speech (TTS)
    console.log('Step 3: Synthesizing speech...');
    const llmResponse = userMessage.data.content; // In reality, get assistant's response
    const ttsRequest = await ttsClient.post('/api/v1/synthesize', {
      text: llmResponse,
      voice: 'en-US-Neural2-A',
      language: 'en',
    });

    expect(ttsRequest.status).toBe(201);
    expect(ttsRequest.data).toHaveProperty('id');
    expect(ttsRequest.data.text).toBe(llmResponse);

    console.log('✓ Complete pipeline executed successfully');
  }, 60000); // 60s timeout for full pipeline
});
